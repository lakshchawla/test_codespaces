{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, 10)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "One of the dimensions in the output is <= 0 due to downsampling in conv2d_6. Consider increasing the input size. Received input shape [None, 1, 1, 64] which would produce output shape with a zero or negative value in a dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/lakshaychawla/Desktop/deep_learning_lab/2_1.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lakshaychawla/Desktop/deep_learning_lab/2_1.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39;49mSequential([\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lakshaychawla/Desktop/deep_learning_lab/2_1.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     layers\u001b[39m.\u001b[39;49mConv2D(\u001b[39m32\u001b[39;49m, (\u001b[39m3\u001b[39;49m, \u001b[39m3\u001b[39;49m), activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m, input_shape\u001b[39m=\u001b[39;49m(\u001b[39m28\u001b[39;49m, \u001b[39m28\u001b[39;49m, \u001b[39m1\u001b[39;49m)),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lakshaychawla/Desktop/deep_learning_lab/2_1.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     layers\u001b[39m.\u001b[39;49mMaxPooling2D((\u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m)),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lakshaychawla/Desktop/deep_learning_lab/2_1.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     layers\u001b[39m.\u001b[39;49mConv2D(\u001b[39m64\u001b[39;49m, (\u001b[39m3\u001b[39;49m, \u001b[39m3\u001b[39;49m), activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lakshaychawla/Desktop/deep_learning_lab/2_1.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     layers\u001b[39m.\u001b[39;49mMaxPooling2D((\u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m)),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lakshaychawla/Desktop/deep_learning_lab/2_1.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     layers\u001b[39m.\u001b[39;49mConv2D(\u001b[39m64\u001b[39;49m, (\u001b[39m3\u001b[39;49m, \u001b[39m3\u001b[39;49m), activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lakshaychawla/Desktop/deep_learning_lab/2_1.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     layers\u001b[39m.\u001b[39;49mMaxPooling2D((\u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m)),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lakshaychawla/Desktop/deep_learning_lab/2_1.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     layers\u001b[39m.\u001b[39;49mConv2D(\u001b[39m64\u001b[39;49m, (\u001b[39m3\u001b[39;49m, \u001b[39m3\u001b[39;49m), activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lakshaychawla/Desktop/deep_learning_lab/2_1.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     layers\u001b[39m.\u001b[39;49mFlatten(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lakshaychawla/Desktop/deep_learning_lab/2_1.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     layers\u001b[39m.\u001b[39;49mDense(\u001b[39m64\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lakshaychawla/Desktop/deep_learning_lab/2_1.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     layers\u001b[39m.\u001b[39;49mDense(\u001b[39m10\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msoftmax\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lakshaychawla/Desktop/deep_learning_lab/2_1.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m ])\n",
      "File \u001b[0;32m~/miniforge3/envs/research/lib/python3.9/site-packages/tensorflow/python/trackable/base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    205\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/research/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/envs/research/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:354\u001b[0m, in \u001b[0;36mConv.compute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mTensorShape(\n\u001b[1;32m    348\u001b[0m             input_shape[:batch_rank]\n\u001b[1;32m    349\u001b[0m             \u001b[39m+\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilters]\n\u001b[1;32m    350\u001b[0m             \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_spatial_output_shape(input_shape[batch_rank \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m :])\n\u001b[1;32m    351\u001b[0m         )\n\u001b[1;32m    353\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m--> 354\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    355\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mOne of the dimensions in the output is <= 0 \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    356\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdue to downsampling in \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m. Consider \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    357\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mincreasing the input size. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    358\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived input shape \u001b[39m\u001b[39m{\u001b[39;00minput_shape\u001b[39m}\u001b[39;00m\u001b[39m which would produce \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    359\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39moutput shape with a zero or negative value in a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    360\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdimension.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    361\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: One of the dimensions in the output is <= 0 due to downsampling in conv2d_6. Consider increasing the input size. Received input shape [None, 1, 1, 64] which would produce output shape with a zero or negative value in a dimension."
     ]
    }
   ],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.1599 - accuracy: 0.9403 - val_loss: 0.2766 - val_accuracy: 0.9041\n",
      "Epoch 2/10\n",
      "361/938 [==========>...................] - ETA: 12s - loss: 0.1455 - accuracy: 0.9468"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/lakshaychawla/Desktop/deep_learning_lab/2_1.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lakshaychawla/Desktop/deep_learning_lab/2_1.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lakshaychawla/Desktop/deep_learning_lab/2_1.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m               loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lakshaychawla/Desktop/deep_learning_lab/2_1.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m               metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lakshaychawla/Desktop/deep_learning_lab/2_1.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_images, train_labels, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(test_images, test_labels))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lakshaychawla/Desktop/deep_learning_lab/2_1.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m test_loss, test_acc \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(test_images, test_labels)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lakshaychawla/Desktop/deep_learning_lab/2_1.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mTest accuracy:\u001b[39m\u001b[39m'\u001b[39m, test_acc)\n",
      "File \u001b[0;32m~/miniforge3/envs/research/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/research/lib/python3.9/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniforge3/envs/research/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/research/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/envs/research/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniforge3/envs/research/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/research/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/envs/research/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniforge3/envs/research/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniforge3/envs/research/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=64, validation_data=(test_images, test_labels))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 190ms/step\n",
      "Predicted class: Pullover\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "img_path = './shirt.jpg'\n",
    "img = image.load_img(img_path, target_size=(28, 28), color_mode='grayscale')\n",
    "\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array /= 255.0\n",
    "\n",
    "prediction = model.predict(img_array)\n",
    "\n",
    "labels = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "          'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "predicted_class = np.argmax(prediction[0])\n",
    "print(f\"Predicted class: {labels[predicted_class]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
